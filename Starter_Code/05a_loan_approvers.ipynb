{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-Ins_Logistic_Regression\n"
     ]
    }
   ],
   "source": [
    "# 8:10 PM\n",
    "# 8:25 PM\n",
    "\n",
    "# break\n",
    "\n",
    "# 8:40 PM\n",
    "# 8:50 PM\n",
    "import os; print(os.path.dirname(os.getcwd()).split('\\\\')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Comment</font>\n",
    "\n",
    "Q) Would you trust your results?\n",
    "\n",
    "Q) How could you improve the models accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Loan Approver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assets</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>income</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210859</td>\n",
       "      <td>0.452865</td>\n",
       "      <td>0.281367</td>\n",
       "      <td>0.628039</td>\n",
       "      <td>0.302682</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395018</td>\n",
       "      <td>0.661153</td>\n",
       "      <td>0.330622</td>\n",
       "      <td>0.638439</td>\n",
       "      <td>0.502831</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.291186</td>\n",
       "      <td>0.593432</td>\n",
       "      <td>0.438436</td>\n",
       "      <td>0.434863</td>\n",
       "      <td>0.315574</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.458640</td>\n",
       "      <td>0.576156</td>\n",
       "      <td>0.744167</td>\n",
       "      <td>0.291324</td>\n",
       "      <td>0.394891</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.463470</td>\n",
       "      <td>0.292414</td>\n",
       "      <td>0.489887</td>\n",
       "      <td>0.811384</td>\n",
       "      <td>0.566605</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     assets  liabilities    income  credit_score  mortgage   status\n",
       "0  0.210859     0.452865  0.281367      0.628039  0.302682     deny\n",
       "1  0.395018     0.661153  0.330622      0.638439  0.502831  approve\n",
       "2  0.291186     0.593432  0.438436      0.434863  0.315574  approve\n",
       "3  0.458640     0.576156  0.744167      0.291324  0.394891  approve\n",
       "4  0.463470     0.292414  0.489887      0.811384  0.566605  approve"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: The following data has been normalized between 0 and 1\n",
    "loan_data = Path= \"C:/Users/CS_Knit_tinK_SC/Documents/My Data Sources/111621/05_loans.csv\"\n",
    "#data = Path('../Resources/loans.csv')\n",
    "df = pd.read_csv(loan_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Separate the Features (X) from the Target (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Comment</font>\n",
    "\n",
    "We have selected features/columns/fields which seem relevant to credit worthiness.\n",
    "\n",
    "Because credit score and income are probably very different numbers (credit score (max 900) vs income max (999999)), the numbers have been scaled/normalized between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assets</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>income</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>mortgage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210859</td>\n",
       "      <td>0.452865</td>\n",
       "      <td>0.281367</td>\n",
       "      <td>0.628039</td>\n",
       "      <td>0.302682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395018</td>\n",
       "      <td>0.661153</td>\n",
       "      <td>0.330622</td>\n",
       "      <td>0.638439</td>\n",
       "      <td>0.502831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.291186</td>\n",
       "      <td>0.593432</td>\n",
       "      <td>0.438436</td>\n",
       "      <td>0.434863</td>\n",
       "      <td>0.315574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.458640</td>\n",
       "      <td>0.576156</td>\n",
       "      <td>0.744167</td>\n",
       "      <td>0.291324</td>\n",
       "      <td>0.394891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.463470</td>\n",
       "      <td>0.292414</td>\n",
       "      <td>0.489887</td>\n",
       "      <td>0.811384</td>\n",
       "      <td>0.566605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.360945</td>\n",
       "      <td>0.823295</td>\n",
       "      <td>0.542451</td>\n",
       "      <td>0.224285</td>\n",
       "      <td>0.328504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.114420</td>\n",
       "      <td>0.107174</td>\n",
       "      <td>0.619564</td>\n",
       "      <td>0.370300</td>\n",
       "      <td>0.047719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.309276</td>\n",
       "      <td>0.692433</td>\n",
       "      <td>0.483730</td>\n",
       "      <td>0.328953</td>\n",
       "      <td>0.304493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.549153</td>\n",
       "      <td>0.301588</td>\n",
       "      <td>0.651869</td>\n",
       "      <td>0.717826</td>\n",
       "      <td>0.602004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.448187</td>\n",
       "      <td>0.217651</td>\n",
       "      <td>0.388670</td>\n",
       "      <td>0.968609</td>\n",
       "      <td>0.606231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      assets  liabilities    income  credit_score  mortgage\n",
       "0   0.210859     0.452865  0.281367      0.628039  0.302682\n",
       "1   0.395018     0.661153  0.330622      0.638439  0.502831\n",
       "2   0.291186     0.593432  0.438436      0.434863  0.315574\n",
       "3   0.458640     0.576156  0.744167      0.291324  0.394891\n",
       "4   0.463470     0.292414  0.489887      0.811384  0.566605\n",
       "..       ...          ...       ...           ...       ...\n",
       "95  0.360945     0.823295  0.542451      0.224285  0.328504\n",
       "96  0.114420     0.107174  0.619564      0.370300  0.047719\n",
       "97  0.309276     0.692433  0.483730      0.328953  0.304493\n",
       "98  0.549153     0.301588  0.651869      0.717826  0.602004\n",
       "99  0.448187     0.217651  0.388670      0.968609  0.606231\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"status\"]\n",
    "X = df.drop(columns=\"status\")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   random_state=1, \n",
    "                                                   stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Create a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Fit (train) or model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Score the model using the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Comment</font>\n",
    "\n",
    "This is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.5466666666666666\n",
      "Testing Data Score: 0.52\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>approve</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prediction   Actual\n",
       "0       deny     deny\n",
       "1       deny  approve\n",
       "2       deny     deny\n",
       "3    approve     deny\n",
       "4       deny     deny"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": predictions,\n",
    "                        \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  9],\n",
       "       [ 3, 10]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.50      0.25      0.33        12\n",
      "        deny       0.53      0.77      0.62        13\n",
      "\n",
      "    accuracy                           0.52        25\n",
      "   macro avg       0.51      0.51      0.48        25\n",
      "weighted avg       0.51      0.52      0.48        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Comment</font>\n",
    "\n",
    "https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "\n",
    "## Accuracy\n",
    "\n",
    "how often the model is correct. However, it can be misleading with imbalanced classes.\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "## Precision\n",
    "\n",
    "ratio of correctly predicted positive observations to the total predicted positive observations. \n",
    "\n",
    "e.g. of all observations classified as a credit risk, how many were actually a credit risk? Did we classify comprehensively and correctly?\n",
    "\n",
    "High precision -> low FPs rate\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "## Recall\n",
    "\n",
    "ratio of correctly predicted positive observations to all predicted observations for that class.\n",
    "\n",
    "e.g. of all observations classified as a credit risk, how did the model classified as being a credit risk?\n",
    "\n",
    "High recall -> low FN rate.\n",
    "\n",
    "recall = tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Comment</font>\n",
    "\n",
    "Q) Would you trust your results? I wouldn't put my money behind it.\n",
    "\n",
    "Q) How could you improve the models accuracy? Give it more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
