# -*- coding: utf-8 -*-
"""
Created on Sat Nov 27 12:40:53 2021

@author: CS_Knit_tinK_SC
"""

# Credit Risk Resampling Techniques

#%%

import warnings
warnings.filterwarnings('ignore')

#%%

import numpy as np
import pandas as pd
from pathlib import Path
from collections import Counter

#%%
#%%

# Read the CSV into DataFrame

#%%
#%%

# Load the data
file_path="C:/Users/CS_Knit_tinK_SC/Documents/GitHub/HW_8_ML_Conf_Imb_Inputs_U11/Resources/lending_data.csv"
#file_path = Path('Resources/lending_data.csv')
df = pd.read_csv(file_path)
print(df.head())

#%%
#%%

# Split the Data into Training and TestingÂ¶

#%%
#%%

# Create our features
X = df.drop(columns="loan_status")

# Create our target
y = df["loan_status"]

#%%

print(X.describe())

#%%

print(y.head())

#%%

# Check the balance of our target values
print(y.value_counts())

#%%

# Create X_train, X_test, y_train, y_test
from sklearn.model_selection import train_test_split
# from library.module import class

X_train, X_test, y_train, y_test = train_test_split(X, 
                                                    y, 
                                                    # Controls the shuffling applied to the data before applying the split.
                                                    # Pass an int for reproducible output across multiple function calls.
                                                    random_state=1, 
                                                    # If not None, data is split in a stratified fashion, using this as the class labels
                                                    # https://www.scribbr.com/methodology/stratified-sampling/
                                                    stratify=y)

#%%
#%%

# Data Pre-Processing

# Scale the training and testing data using the StandardScaler from sklearn. 
# Remember that when scaling the data, you only scale the features data (X_train and X_testing).

#%%
#%%

# Create the StandardScaler instance to normalize the values individually, before applying the ML model, to get it w/n distr of mean value of 0 and std dev of 1
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
#%%

new_X_train=get_dummies(X_train)

#%%

scaler.fit(X_train)
print(scaler.mean_)

#%%
