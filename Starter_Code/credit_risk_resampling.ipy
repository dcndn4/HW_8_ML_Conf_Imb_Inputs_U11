# -*- coding: utf-8 -*-
"""
Created on Sat Nov 27 12:40:53 2021

@author: CS_Knit_tinK_SC
"""

# Credit Risk Resampling Techniques

#%%

import warnings
warnings.filterwarnings('ignore')

#%%

import numpy as np
import pandas as pd
from pathlib import Path
from collections import Counter

#%%
#%%

# Read the CSV into DataFrame

#%%
#%%

# Load the data
file_path="C:/Users/CS_Knit_tinK_SC/Documents/GitHub/HW_8_ML_Conf_Imb_Inputs_U11/Resources/lending_data.csv"
#file_path = Path('Resources/lending_data.csv')
df = pd.read_csv(file_path)
print(df.head())

#%%
#%%

# Split the Data into Training and Testing¶

#%%
#%%

# Create our features
X = df.drop(columns="loan_status")

# Create our target
y = df["loan_status"]

#%%

print(X.describe())

#%%

print(y.head())

#%%

# Check the balance of our target values
print(y.value_counts())

#%%

# Create X_train, X_test, y_train, y_test
from sklearn.model_selection import train_test_split
# from library.module import class

X_train, X_test, y_train, y_test = train_test_split(X, 
                                                    y, 
                                                    # Controls the shuffling applied to the data before applying the split.
                                                    # Pass an int for reproducible output across multiple function calls.
                                                    random_state=1, 
                                                    # If not None, data is split in a stratified fashion, using this as the class labels
                                                    # https://www.scribbr.com/methodology/stratified-sampling/
                                                    stratify=y)

#%%
#%%

# Data Pre-Processing

# Scale the training and testing data using the StandardScaler from sklearn. 
# Remember that when scaling the data, you only scale the features data (X_train and X_testing).

#%%
#%%

# Create the StandardScaler instance to normalize the values individually, before applying the ML model, to get it w/n distr of mean value of 0 and std dev of 1
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
#%%

# Dummy Encoding (Binary Encoded Data)¶
# .get_dummies avoids this hassle entirely. All are 0s and 1s.  [from #1b exercise]
# Binary encoding using Pandas (single column)
# loans_binary_encoded = pd.get_dummies(loans_df, columns=["gender"])
# print(loans_binary_encoded.head())

new_X_train=pd.get_dummies(X_train, columns=["homeowner"])

#%%

scaler.fit(new_X_train)
print(f'the scaler mean is {scaler.mean_}')

#%%

# Fit the Standard Scaler with the training data
# When fitting scaling functions, only train on the training dataset

#%%


# Creating the scaler instance
data_scaler = StandardScaler()

# Fitting the scaler
data_scaler.fit(new_x_train)

#%%

# Scale the training and testing data

# loans_data_scaled = data_scaler.transform(new_x_train)
# loans_data_scaled[:5]

X_train_scaled = data_scaler.transform(new_X_train)
X_test_scaled = data_scaler.transform(X_test)

#%%

# continue 01b and 03b
